{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Virgin' now corrected to 'Unmarried' in IGIMS'...</td>\n",
       "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sumedha Sehra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                  date  \\\n",
       "0    Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "1     Daisy Mowke  03 Aug 2017,Thursday   \n",
       "2  Arshiya Chopra  03 Aug 2017,Thursday   \n",
       "3   Sumedha Sehra  03 Aug 2017,Thursday   \n",
       "\n",
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  Virgin' now corrected to 'Unmarried' in IGIMS'...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "\n",
       "                                           read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/raksh...   \n",
       "1  http://www.hindustantimes.com/bollywood/malaik...   \n",
       "2  http://www.hindustantimes.com/patna/bihar-igim...   \n",
       "3  http://indiatoday.intoday.in/story/abu-dujana-...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "\n",
       "                                               ctext  \n",
       "0  The Daman and Diu administration on Wednesday ...  \n",
       "1  From her special numbers to TV?appearances, Bo...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('news_summary.csv')#,encoding=\"ISO-8859-1\")\n",
    "dataset.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Daman and Diu administration on Wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media\n",
      "18\n",
      "[['The Daman and Diu administration on Wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media', 'The union territory?s administration was forced to retreat within 24 hours of issuing the circular that made it compulsory for its staff to celebrate Rakshabandhan at workplace', '?It has been decided to celebrate the festival of Rakshabandhan on August 7', ' In this connection, all offices/ departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues,? the order, issued on August 1 by Gurpreet Singh, deputy secretary (personnel), had said', 'To ensure that no one skipped office, an attendance report was to be sent to the government the next evening', 'The two notifications ? one mandating the celebration of Rakshabandhan (left) and the other withdrawing the mandate (right) ? were issued by the Daman and Diu administration a day apart', ' The circular was withdrawn through a one-line order issued late in the evening by the UT?s department of personnel and administrative reforms', '?The circular is ridiculous', ' There are sensitivities involved', ' How can the government dictate who I should tie rakhi to? We should maintain the professionalism of a workplace? an official told Hindustan Times earlier in the day', ' She refused to be identified', 'The notice was issued on Daman and Diu administrator and former Gujarat home minister Praful Kodabhai Patel?s direction, sources said', 'Rakshabandhan, a celebration of the bond between brothers and sisters, is one of several Hindu festivities and rituals that are no longer confined of private, family affairs but have become tools to push politic al ideologies', 'In 2014, the year BJP stormed to power at the Centre, Rashtriya Swayamsevak Sangh (RSS) chief Mohan Bhagwat said the festival had ?national significance? and should be celebrated widely ?to protect Hindu culture and live by the values enshrined in it?', ' The RSS is the ideological parent of the ruling BJP', 'Last year, women ministers in the Modi government went to the border areas to celebrate the festival with soldiers', ' A year before, all cabinet ministers were asked to go to their constituencies for the festival', ''], 'The Daman and Diu administration on Wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media', 'The union territory?s administration was forced to retreat within 24 hours of issuing the circular that made it compulsory for its staff to celebrate Rakshabandhan at workplace', '?It has been decided to celebrate the festival of Rakshabandhan on August 7', ' In this connection, all offices/ departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues,? the order, issued on August 1 by Gurpreet Singh, deputy secretary (personnel), had said', 'To ensure that no one skipped office, an attendance report was to be sent to the government the next evening', 'The two notifications ? one mandating the celebration of Rakshabandhan (left) and the other withdrawing the mandate (right) ? were issued by the Daman and Diu administration a day apart', ' The circular was withdrawn through a one-line order issued late in the evening by the UT?s department of personnel and administrative reforms', '?The circular is ridiculous', ' There are sensitivities involved', ' How can the government dictate who I should tie rakhi to? We should maintain the professionalism of a workplace? an official told Hindustan Times earlier in the day', ' She refused to be identified', 'The notice was issued on Daman and Diu administrator and former Gujarat home minister Praful Kodabhai Patel?s direction, sources said', 'Rakshabandhan, a celebration of the bond between brothers and sisters, is one of several Hindu festivities and rituals that are no longer confined of private, family affairs but have become tools to push politic al ideologies', 'In 2014, the year BJP stormed to power at the Centre, Rashtriya Swayamsevak Sangh (RSS) chief Mohan Bhagwat said the festival had ?national significance? and should be celebrated widely ?to protect Hindu culture and live by the values enshrined in it?', ' The RSS is the ideological parent of the ruling BJP', 'Last year, women ministers in the Modi government went to the border areas to celebrate the festival with soldiers', ' A year before, all cabinet ministers were asked to go to their constituencies for the festival', '']\n",
      "0       Daman & Diu revokes mandatory Rakshabandhan in...\n",
      "1       Malaika slams user who trolled her for 'divorc...\n",
      "2       Virgin' now corrected to 'Unmarried' in IGIMS'...\n",
      "3       Aaj aapne pakad liya: LeT man Dujana before be...\n",
      "4       Hotel staff to get training to spot signs of s...\n",
      "                              ...                        \n",
      "4509    Rasna seeking ?250 cr revenue from snack categ...\n",
      "4510    Sachin attends Rajya Sabha after questions on ...\n",
      "4511    Shouldn't rob their childhood: Aamir on kids r...\n",
      "4512    Asha Bhosle gets ?53,000 power bill for unused...\n",
      "4513    More than half of India's languages may die in...\n",
      "Name: headlines, Length: 4395, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.dropna(how='any',axis=0) \n",
    "x = dataset['ctext']\n",
    "y = dataset['text']\n",
    "# x.datatype\n",
    "# print(x[0])\n",
    "t=[]\n",
    "# print(len(x[0]))\n",
    "# for i in range(len(x)):\n",
    "#     for j in range(len(x[i])):\n",
    "#         t.append(x[j].split(\".\"))\n",
    "# print(t)\n",
    "\n",
    "t.append(x[0].split(\".\"))\n",
    "print(t[0][0])\n",
    "print(len(t[0]))\n",
    "for i in range(len(t[0])):\n",
    "    t.append(t[0][i])\n",
    "print(t)\n",
    "\n",
    "\n",
    "# s= pd.Series([x[0],np.nan])\n",
    "# print(s)\n",
    "# li =[]\n",
    "# s.str.split(pat=\".\")\n",
    "# print(s[0])\n",
    "# for i in x[0]:\n",
    "#     c=0\n",
    "#     if(i != '.'):\n",
    "#         c+=1\n",
    "#     else:\n",
    "#         li.append()\n",
    "        \n",
    "headline = dataset['headlines']\n",
    "print(headline)\n",
    "# del dataset\n",
    "# headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_sentence(w,f):\n",
    "#     w = w.lower().strip()\n",
    "\n",
    "#     # creating a space between a word and the punctuation following it\n",
    "#     # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "#     # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "#     w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "#     w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "#     # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "#     w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "#     w = w.rstrip().strip()\n",
    "\n",
    "#     # adding a start and an end token to the sentence\n",
    "#     # so that the model know when to start and stop predicting.\n",
    "#     if(f==0):\n",
    "#         w = '<start> '+ w + ' <end>'\n",
    "#         f=1\n",
    "#     return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(lang):\n",
    "#     lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "  \n",
    "#     lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "#     tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "#     tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "#     return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 50)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'TensorShape' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-e9f1b9ce4631>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'TensorShape' object is not callable"
     ]
    }
   ],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\")\n",
    "embeddings = embed(t[0])\n",
    "print(embeddings.shape)\n",
    "embed()\n",
    "# embeddings.shape([0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# embeddings = embed([\"cat is on the mat\", \"dog is in the fog\"])\n",
    "# print(embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 50)\n"
     ]
    }
   ],
   "source": [
    "# hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\",output_shape=[16],input_shape=[],dtype = tf.string)\n",
    "# hub_layer(t[0][0])\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor Shape : (4395, 5801) Target Tensor Shape : (4395, 96)\n",
      "Preprocessed Text : \n",
      " <start> start start start start start the daman and diu administration on wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media . the union territory ? s administration was forced to retreat within hours of issuing the circular that made it compulsory for its staff to celebrate rakshabandhan at workplace . ? it has been decided to celebrate the festival of rakshabandhan on august . in this connection , all offices departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues , ? the order , issued on august by gurpreet singh , deputy secretary personnel , had said . to ensure that no one skipped office , an attendance report was to be sent to the government the next evening . the two notifications ? one mandating the celebration of rakshabandhan left and the other withdrawing the mandate right ? were issued by the daman and diu administration a day apart . the circular was withdrawn through a one line order issued late in the evening by the ut ? s department of personnel and administrative reforms . ? the circular is ridiculous . there are sensitivities involved . how can the government dictate who i should tie rakhi to ? we should maintain the professionalism of a workplace ? an official told hindustan times earlier in the day . she refused to be identified . the notice was issued on daman and diu administrator and former gujarat home minister praful kodabhai patel ? s direction , sources said . rakshabandhan , a celebration of the bond between brothers and sisters , is one of several hindu festivities and rituals that are no longer confined of private , family affairs but have become tools to push politic al ideologies . in , the year bjp stormed to power at the centre , rashtriya swayamsevak sangh rss chief mohan bhagwat said the festival had ? national significance ? and should be celebrated widely ? to protect hindu culture and live by the values enshrined in it ? . the rss is the ideological parent of the ruling bjp . last year , women ministers in the modi government went to the border areas to celebrate the festival with soldiers . a year before , all cabinet ministers were asked to go to their constituencies for the festival . end end end end end <end>\n",
      "Tokenized Text INP : \n",
      " [44 11 11 ...  0  0  0]\n",
      "Tokenized Text OUT : \n",
      " [   11     1     1     1     1     1     3   920     9   285  2138  8029\n",
      "    10  8030    15  3702    59   300    17   116    23  2139    16   118\n",
      "     6  3347  8031     6    56  1101  3703    13     3  2023     9  6420\n",
      "    13   630     4     3   920    19   659     6  2291     3   425   333\n",
      "   348     9  2292     3  3348    29    23   305 10963    28   537    10\n",
      "    19   374    13   323   231     4     2     2     2     2     2    12\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "Headline Text : \n",
      " <start> start start start start start daman diu revokes mandatory rakshabandhan in offices order end end end end end <end>\n",
      "Headline Tokenized : \n",
      " [   3    2    2    2    2    2 2721 2722 2723  632 2724    6 1597  633\n",
      "    1    1    1    1    1    4    0    0    0    0    0    0    0    0\n",
      "    0]\n"
     ]
    }
   ],
   "source": [
    "# f=0\n",
    "# x = [preprocess_sentence(w,f) for w in x]\n",
    "# y = [preprocess_sentence(w,f) for w in y]\n",
    "# headline = [preprocess_sentence(w,f) for w in headline]\n",
    "# x_train, inp_lang = tokenize(x)\n",
    "# y_train, targ_lang = tokenize(y)\n",
    "# headline_train , headline_lang = tokenize(headline)\n",
    "# print(\"Input Tensor Shape :\" , x_train.shape , \"Target Tensor Shape :\" , y_train.shape)\n",
    "# print(\"Preprocessed Text : \\n\" , x[0])\n",
    "# # embeddings = embed(x[0])\n",
    "# print(\"Tokenized Text INP : \\n\" , x_train[0])\n",
    "# print(\"Tokenized Text OUT : \\n\" , y_train[0])\n",
    "\n",
    "# print(\"Headline Text : \\n\" , headline[0])\n",
    "# print(\"Headline Tokenized : \\n\" , headline_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    The code of encoder is used for text summarization. The model needs an initial_state which is the headline of the article.\n",
    "    The input is supposed to be padded sequence for initial state as well as for the input. The model cuurently implements\n",
    "    GRU for the encoder sequence as there is some bug with using lstm with bidirectional. Bidirectional was also tried with \n",
    "    GRU but same bug occured.\n",
    "    \n",
    "    The initialization is based on docuemnt context vector paper referenced from \n",
    "    https://arxiv.org/pdf/1807.08000.pdf paper named \n",
    "    Abstractive and Extractive Text Summarization using DocumentContext Vector and Recurrent Neural Networks.\n",
    "    \n",
    "    However the logic is modeified. The model takes the preprocessed tokenized padded sequence as input for initials state\n",
    "    and the then it is passed through the embedded vector and the size of the output vector after embedding is (batch_size , time , embedding size)\n",
    "    after this the model is averaged about the time axis and gives the output as (batch_size , embedding size).\n",
    "    This tensor is then passed as input to dence vector and is used to give the output size of (batch_zie , lgur_hidden_units)\n",
    "    '''\n",
    "    def __init__(self,units = 16,activation='tanh',recurrent_activation='sigmoid',return_state=True,return_sequence=False , vocab_size=30000 , embedding_dim=30 , batch_size=2):\n",
    "        super (Encoder , self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.recurrent_activation = recurrent_activation\n",
    "        self.return_state = return_state\n",
    "        self.return_sequence = return_sequence\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
    "#         self.lstm = tf.keras.layers.LSTM(units=self.units , activation=self.activation , recurrent_activation=self.activation, return_sequences=self.return_sequence , return_state=self.return_state)\n",
    "        self.gru = tf.keras.layers.GRU(units=self.units , activation=self.activation , recurrent_activation=self.activation, return_sequences=self.return_sequence , return_state=self.return_state)\n",
    "#         self.bidirectional = tf.keras.layers.Bidirectional(self.gru)\n",
    "        self.dense = tf.keras.layers.Dense(units=self.units , input_shape = (self.embedding_dim,))\n",
    "        print(self.gru)\n",
    "        print(self.dense)\n",
    "    \n",
    "    def call(self,x,headline):\n",
    "        x = self.embedding(x)\n",
    "        headline = self.embedding(headline)\n",
    "        headline = tf.reduce_mean(headline,axis=1)\n",
    "        headline  = self.dense(headline)\n",
    "        output , state = self.gru(x,initial_state=headline)\n",
    "        print(headline)\n",
    "        return output , state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.recurrent_v2.GRU object at 0x0000021FB7A97F28>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000021FC43B80B8>\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.01274545  0.00377362  0.00176518  0.01666837  0.00011586 -0.00791561\n",
      "  -0.00348736 -0.01001901 -0.02082361  0.00328003 -0.00442921 -0.00485594\n",
      "   0.00675421 -0.01471758  0.00612056  0.00763087]\n",
      " [-0.01447946  0.00330228  0.00396879  0.0091158  -0.00728692 -0.00592501\n",
      "  -0.000117   -0.0094883  -0.01375795  0.00186321 -0.00284222 -0.00010325\n",
      "  -0.002235   -0.0089999   0.00074972  0.00753917]], shape=(2, 16), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.01094229 -0.0115445   0.01160178 -0.03359373 -0.01112978  0.07763909\n",
      "  -0.03779947  0.02282105 -0.0381206   0.05562177 -0.03530743 -0.01319344\n",
      "   0.02424197 -0.00312998  0.05153564  0.00087946]\n",
      " [ 0.01094229 -0.0115445   0.01160178 -0.03359373 -0.01112978  0.07763909\n",
      "  -0.03779947  0.02282105 -0.0381206   0.05562177 -0.03530743 -0.01319344\n",
      "   0.02424197 -0.00312998  0.05153564  0.00087946]], shape=(2, 16), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.01094229 -0.0115445   0.01160178 -0.03359373 -0.01112978  0.07763909\n",
      "  -0.03779947  0.02282105 -0.0381206   0.05562177 -0.03530743 -0.01319344\n",
      "   0.02424197 -0.00312998  0.05153564  0.00087946]\n",
      " [ 0.01094229 -0.0115445   0.01160178 -0.03359373 -0.01112978  0.07763909\n",
      "  -0.03779947  0.02282105 -0.0381206   0.05562177 -0.03530743 -0.01319344\n",
      "   0.02424197 -0.00312998  0.05153564  0.00087946]], shape=(2, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# encoder(x_train[:2] , headline_train[:2])\n",
    "output, state = encoder(x_train[:2] , headline_train[:2])\n",
    "print(output)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "#         print(\"Score is :\",score)\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.0260665   0.00831839  0.0087458   0.02841727  0.00547543  0.00237772\n",
      "   0.0556828  -0.02215733  0.00440013  0.02172088  0.02116591 -0.01438401\n",
      "  -0.00582038  0.01565367 -0.0174822   0.00196129]\n",
      " [ 0.0260665   0.00831839  0.0087458   0.02841727  0.00547543  0.00237772\n",
      "   0.0556828  -0.02215733  0.00440013  0.02172088  0.02116591 -0.01438401\n",
      "  -0.00582038  0.01565367 -0.0174822   0.00196129]], shape=(2, 16), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.5]\n",
      "  [0.5]]\n",
      "\n",
      " [[0.5]\n",
      "  [0.5]]], shape=(2, 2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(state, output)\n",
    "print(attention_result)\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, units = 16,activation='tanh',recurrent_activation='sigmoid',return_state=True,return_sequence=False , vocab_size=30000 , embedding_dim=30 , batch_size=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.recurrent_activation = recurrent_activation\n",
    "        self.return_state = return_state\n",
    "        self.return_sequence = return_sequence\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "#         self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "#                                        return_sequences=True,\n",
    "#                                        return_state=True,\n",
    "#                                        recurrent_initializer='glorot_uniform')\n",
    "        self.gru = tf.keras.layers.GRU(units=self.units , activation=self.activation , recurrent_activation=self.activation, return_sequences=self.return_sequence , return_state=self.return_state)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.units)\n",
    "\n",
    "    def call(self, x, hidden, output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[1]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (2, 30000)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder()\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((2, 1)),\n",
    "                                      output, state)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=313399, shape=(2, 30000), dtype=float32, numpy=\n",
       "array([[-1.5908470e-03, -5.2676239e-04, -7.7945594e-04, ...,\n",
       "         3.1645558e-04, -1.8402003e-05,  4.2581014e-05],\n",
       "       [-1.5908470e-03, -5.2676239e-04, -7.7945594e-04, ...,\n",
       "         3.1645558e-04, -1.8402003e-05,  4.2581014e-05]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
